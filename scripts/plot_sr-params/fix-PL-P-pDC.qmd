---
title: "PhyloSim Changes"
author: "A.I."
format:
  html:
    number-sections: true
editor: visual
---

```{r}
#| warning: false
library(PhyloSim)
library(parallel)
library(dplyr)
library(tidyverse)
library(lattice)
library(ggplot2)
library(metafor)
library(MASS)
library(viridis)
# root <- "~/Uni/Master/MA/" # work from local machine
root <- "~/cyber_synch/" # work from uni bayreuth server
```

**Here, I plot the effects of N, NL, nDC while all P properties are fixed**

## Data preparation

```{r}
#| eval: false

# load in runs with exp kernel
runsRaw  <- readRDS(paste0(root, "/local/runs/plot_sr-params/mat/fix-PL-P-pDC.rds"))
```

```{r}
#| eval: false

# get conspecific neighbors and proper naming
runsRaw  <- getConNeigh(runsRaw, radius = 5)
```

```{r}
saveRDS(runsRaw, paste0(root, "/local/runs/plot_sr-params/temp/fix-PL-P-pDC_conMax.rds"))
runsRaw  <- readRDS(paste0(root, "/local/runs/plot_sr-params/temp/fix-PL-P-pDC_conMax.rds"))
```

```{r}
# make the runs more slim
# runs_ix <- lapply(runsRaw, function(x){
#   x$Output <- x$Output[101:300]
#   return(x)
# })
```

```{r}
namesShort <- names(runsRaw) %>%
  stringr::str_remove("_disp.+") %>% 
  stringr::str_replace("Cut", "-C") %>% 
  stringr::str_replace("Cut", "-C") %>% 
  stringr::str_replace("pdd", "P") %>% 
  stringr::str_replace("ndd", "N") %>% 
  stringr::str_replace_all("Var", "-L")

```

```{r}
names(runsRaw) <- namesShort
```

```{r}
S <- getSpecTime(runsRaw, plot = FALSE)
```

```{r}
# Extract mean and sd of species richness
Sp <- sapply(S, function(x){
  vals <- x$spec_rich[99:200]
  c(mean = mean(vals), sd = sd(vals))
}) %>% t() %>% as.data.frame()
colnames(Sp) <- c("meanSR", "sdSR")
Sp$params <- namesShort 

# Parse parameters correctly (nDD: N, NL, C)
Sp2 <- Sp %>%
  extract(params,
          into = c("N","NL","C"),
          regex = "N([0-9.]+)-L([0-9.]+)-C([0-9]+)",
          remove = FALSE) %>%
  mutate(N  = as.numeric(N),
         NL = as.numeric(NL),
         C  = as.numeric(C))

# Get the N=0 baseline (only exists for NL=20)
base0 <- Sp2 %>% filter(N == 0, NL == 20)

# All NL values present in the data
all_NL <- sort(unique(Sp2$NL))

# For each C value, replicate the N=0 point across all NL values
base0_expanded <- do.call(rbind, lapply(unique(base0$C), function(c_val) {
  base_c <- base0[base0$C == c_val, ]
  expanded <- base_c[rep(1, length(all_NL)), ]
  expanded$NL <- all_NL
  expanded$params <- paste0("N0-L", all_NL, "-C", c_val, "_N1-L5-C1")
  return(expanded)
}))

# Remove the original N=0, NL=20 entries to avoid duplicates
Sp2_filtered <- Sp2 %>% filter(!(N == 0 & NL == 20))

# Bind expanded baseline back, neutralize sdSR for replicated rows
Sp2_final <- bind_rows(Sp2_filtered, base0_expanded) %>% 
  mutate(sdSR = case_when(
    N == 0 & NL != 20 ~ NA_real_,
    TRUE ~ sdSR
  ))

```

```{r}
#| fig-width: 10
#| fig-height: 5


# Create the baseline point for each C value
baseline_unique <- Sp2_final %>% 
  filter(N == 0 & NL == 20) %>%
  group_by(C) %>%
  slice(1) %>%
  ungroup()

# Create complete dataset including baseline for lines
# but keep separate datasets for different point styling
complete_data <- Sp2_final %>% filter(N > 0)

# Plot
plotNDD <- ggplot() +
  # Plot lines connecting all points (including baseline)
  geom_line(data = Sp2_final, 
            aes(x = N, y = meanSR, color = factor(NL), group = NL), 
            size = .8) +
  # Plot colored points for N > 0
  geom_point(data = complete_data, 
             aes(x = N, y = meanSR, color = factor(NL)), 
             size = 2, position = position_dodge(width = 0.1)) +
  geom_errorbar(data = complete_data,
                aes(x = N, y = meanSR, color = factor(NL),
                    ymin = meanSR - sdSR, ymax = meanSR + sdSR),
                width = 0.05, alpha = 1,
                position = position_dodge(width = 0.075)) +
  # Add the baseline points in black (this will overlay the colored points at N=0)
  geom_point(data = baseline_unique, 
             aes(x = N, y = meanSR), 
             color = "black", size = 2, shape = 3) +
  geom_errorbar(data = baseline_unique,
                aes(x = N, y = meanSR, ymin = meanSR - sdSR, ymax = meanSR + sdSR),
                color = "black", width = 0.005, alpha = 1) +
  facet_wrap(~ C, ncol = 3, scales = "fixed",
             labeller = labeller(C = function(x) paste("nDD kernel =", x))) +
  labs(x = "nDD strength",
       y = "mean species richness",
       color = "nDD\nspecificity") +
  theme_classic(base_size = 16) +
  theme(
    strip.background = element_blank(),
    legend.position = "right",
    strip.text = element_text(size = 15, margin = margin(b = -20)),
    plot.margin = margin(20, 20, 20, 20),
    panel.spacing = unit(1, "lines"),
    axis.title.x = element_text(margin = margin(t = 15)),
    axis.title.y = element_text(margin = margin(r = 15)),
    panel.grid.major.y = element_line(color = "grey90", size = 0.2),
    panel.grid.minor.y = element_line(color = "grey95", size = 0.2),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) + 
  coord_cartesian(clip = "off") +
  scale_color_viridis_d(option = "plasma") +
  scale_x_continuous(breaks = seq(0, 1, by = 0.2))

print(plotNDD)
```

```{r}
# pdf(paste0(root, "local/figures/plot_sr-params/nddEffect.pdf"), width = 10, height = 5, onefile = TRUE, useDingbats = FALSE)
print(plotNDD)
# dev.off()
```

Next, we convert the matrix data into tabular data. With the argument detailedParams we include the parameter settings a seperate cols. We save the tabular data.

```{r}
#| eval: false


# reduce size of data by burn in period until equilibrium is reached
runsFilt <- lapply(runsRaw, function(x){
  x$Output <- x$Output[99:200]
  x$Model$runs <- x$Model$runs[99:200]
  return(x)
})

# convert matrices to tabular data. This is done parallel, as it takes longer
cl <- makeCluster(length(runsFilt)/2)
clusterExport(cl, c("getMatToTab", "runsFilt"))
tab <- parLapply(cl = cl, X = runsFilt, fun = function(x) getMatToTab(x, detailedParams = TRUE))

saveRDS(tab, paste0(root, "local/runs/plot_sr-params/tab/fix-P-PL-pDCMax.rds"))
```

```{r}
# tab <- readRDS(paste0(root, "local/runs/plot_sr-params/tab/fix-P-PL-pDC.rds"))
tab <- readRDS(paste0(root, "local/runs/plot_sr-params/tab/fix-P-PL-pDCMax.rds"))
```

```{r}
# keep only first timespot in census

cores <- length(tab) / 2
cl <- makeCluster(30)

clusterEvalQ(cl, {
  library(dplyr)
})

tabS <- parLapply(cl, tab, function(x) {
  x %>%
    filter(abund > 100) %>%
    mutate(specIdCen = paste0(specId, census)) %>%
    select(-indId)
})

stopCluster(cl)
```

### Metafor analysis: correcting for uncertainty

```{r}
#| eval: false

cl <- makeCluster(length(tabS)/2)
clusterEvalQ(cl, {
  library(PhyloSim)
})
mcS_err <- parLapply(cl, tabS, function(x) {
  specIDs <- unique(x$specIdCen)
  res <- vector("list", length(specIDs))
  
  i <- 1
  for (sID in specIDs) {
    dat <- x[x$specIdCen == sID, ]
    mod <- glm(mortNextGen ~ con, data = dat, family = binomial())
    sfm <- summary(mod)$coefficients
    # corFac <- nrow(getCircularOffsets(max(x$pDC, x$nDC))) / 4
    vc <- vcov(mod)[c("(Intercept)", "con"), c("(Intercept)", "con")] # * corFac # correction factor

    mort0 <- plogis(coef(mod)[1])
    mort1 <- plogis(coef(mod)[1] + coef(mod)[2]) # * corFac) # correction factor
    
    res[[i]] <- list(
      specId = sID,
      abund = dat$abund[1],
      mort_change = mort1 - mort0,
      coef = coef(mod)[c(1,2)], # * c(1, corFac), # correction factor
      vcov = vc
    )
    i <- i + 1
  }
  return(res)
})

# Stop the cluster
stopCluster(cl)
```

## compute variance of the marginal effect through a "posterior" simulation

```{r}
#| eval: false

cl <- makeCluster(length(mcS_err) / 2)
mcS_err_sim <- parLapply(cl, mcS_err, function(x){
  lapply(x, function(y){
    sim <- MASS::mvrnorm(n = 100, mu = c(y$coef[1], y$coef[2]), Sigma = y$vcov)
    mort0 <- plogis(sim[, 1])
    mort1 <- plogis(sim[, 1] + sim[, 2])
    mort_diff <- mort1 - mort0
    
    return(data.frame(
      abund = y$abund,
      specId = y$specId,
      mean = mean(mort_diff),
      se = sd(mort_diff),
      ci_low = quantile(mort_diff, 0.025),
      ci_high = quantile(mort_diff, 0.975)
    ))
  })
})
# Stop the cluster
stopCluster(cl)
```

## unlist inner lists and add log abund

```{r}
#| eval: false

m4 <- lapply(mcS_err_sim, function(group) {
  do.call(rbind, group)
})

m4 <- lapply(m4, function(group) {
  row.names(group) <- NULL
  group <- group %>% 
    mutate(log_N = log(abund))
  return(group)
})
```

## fitting model

```{r}
#| eval: false

dat_meta <- lapply(m4, function(x) {
  escalc(measure = "GEN", yi = mean, sei = se, slab = specId, data = x)
})
```

```{r}
#| eval: false

# # Detect available cores and create a cluster
# cl <- makeCluster(length(dat_meta))
# 
# # Export needed objects and packages to the workers
# clusterExport(cl, varlist = c("dat_meta"), envir = environment())
# 
# # Run in parallel
# metamod <- parLapply(cl, dat_meta, function(x) {
#   metafor::rma(
#     yi = yi,
#     vi = vi,
#     mods = ~ log_N,
#     method = "REML",
#     data = x
#   )
# })
# 
# # Stop cluster
# stopCluster(cl)
# 
# names(metamod) <- namesShort
```

```{r}
cl <- makeCluster(length(dat_meta) / 2)
clusterExport(cl, varlist = c("dat_meta"), envir = environment())

metamod <- parLapply(cl, dat_meta, function(x) {
  tryCatch({
    metafor::rma(
      yi = yi,
      vi = vi,
      mods = ~ log_N,
      method = "REML",
      data = x
    )
  }, error = function(e) {
    return(NULL)  # Return NULL for failed models
  })
})

stopCluster(cl)

# Remove NULL elements and keep names aligned
failed_indices <- sapply(metamod, is.null)
namesShort <- names(metamod)
metamod <- metamod[!failed_indices]
names(metamod) <- namesShort[!failed_indices]

# Report which models failed
if(any(failed_indices)) {
  cat("Failed models:", paste(namesShort[failed_indices], collapse = ", "), "\n")
}
```

```{r}

# deleting one scenario
# 
# saveRDS(dat_meta, paste0(root, "local/runs/plot_sr-params/metafor/fix-PL-P-pDC_datmetaMax.rds"))
# saveRDS(metamod, paste0(root, "local/runs/plot_sr-params/metafor/fix-PL-P-pDC_metamodMax.rds"))


metamod <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-PL-P-pDC_metamodMax.rds"))
dat_meta <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-PL-P-pDC_datmetaMax.rds"))
namesShort <- names(metamod)

```

## predictions

### log_N

```{r}
#| fig-width: 6
#| fig-height: 6

cb_colors <- c(
  "#029E73",  # Green
  "#0173B2",  # Blue
  "#DE8F05",  # Orange
  "#CC78BC",  # Purple
  "firebrick"   # Brown
)

## --- build predictions (as you had) ---
pred <- lapply(dat_meta, function(x){
  expand_grid(log_N = seq(min(x$log_N, na.rm = TRUE),
                          max(x$log_N, na.rm = TRUE),
                          length.out = 1000))
})
pred <- lapply(pred, function(x){
  x$abund <- exp(x$log_N)
  x
})
pred <- lapply(seq_along(pred), function(i){
  x <- pred[[i]]
  y <- metamod[[i]]
  cbind(x, predict(object = y, newmods = x$log_N))
})
names(pred) <- namesShort

## --- helper: parse N, NL, C from the *second* chunk ---
extract_params <- function(nm) {
  rhs <- sub(".*_", "", nm)                 # "N0.2-L10-C3"
  N  <- as.numeric(sub("N([0-9.]+).*", "\\1", rhs))
  NL <- as.numeric(sub(".*-L([0-9.]+).*", "\\1", rhs))
  C  <- as.numeric(sub(".*-C([0-9.]+)$",   "\\1", rhs))
  data.frame(N = N, NL = NL, C = C)
}

## --- bind list to df with parsed params ---
pred_df_raw <- do.call(rbind, lapply(seq_along(pred), function(i) {
  df <- pred[[i]]
  pars <- extract_params(names(pred)[i])
  df$scenario <- names(pred)[i]
  df$N  <- pars$N
  df$NL <- pars$NL
  df$C  <- pars$C
  df
}))

## --- normalize predict() columns ---
if ("pred" %in% names(pred_df_raw))   names(pred_df_raw)[names(pred_df_raw)=="pred"]   <- "fitted"
if ("fit"  %in% names(pred_df_raw))   names(pred_df_raw)[names(pred_df_raw)=="fit"]    <- "fitted"
if ("ci.lb" %in% names(pred_df_raw))  pred_df_raw$ci_lower <- pred_df_raw$ci.lb
if ("ci.ub" %in% names(pred_df_raw))  pred_df_raw$ci_upper <- pred_df_raw$ci.ub

pred_df <- pred_df_raw %>% filter(N != 0)

## --- null models for each C value ---
null_nameC1 <- "P1-L5-C1_N0-L20-C1"
null_dataC1 <- if (null_nameC1 %in% pred_df_raw$scenario) pred_df_raw[pred_df_raw$scenario == null_nameC1, ] else NULL

null_nameC3 <- "P1-L5-C1_N0-L20-C3"
null_dataC3 <- if (null_nameC3 %in% pred_df_raw$scenario) pred_df_raw[pred_df_raw$scenario == null_nameC3, ] else NULL

null_nameC5 <- "P1-L5-C1_N0-L20-C5"
null_dataC5 <- if (null_nameC5 %in% pred_df_raw$scenario) pred_df_raw[pred_df_raw$scenario == null_nameC5, ] else NULL

## --- CHANGED: build separate plots per (N, C), lines = NL levels ---
library(ggplot2)

# common axes
x_range <- range(pred_df$abund[pred_df$abund > 0 & is.finite(pred_df$abund)], na.rm = TRUE)
y_range <- range(c(pred_df$ci_lower, pred_df$ci_upper), na.rm = TRUE)

# order NL nicely for legend (now NL is color)
pred_df$NL_fac <- factor(pred_df$NL, levels = sort(unique(pred_df$NL)))

# CHANGED: now combinations are N and C
combos <- unique(pred_df[c("N", "C")])
combos <- combos[order(combos$N, combos$C), ]

plots_list <- vector("list", nrow(combos))
names(plots_list) <- paste0("N", combos$N, "_C", combos$C)

for (i in seq_len(nrow(combos))) {
  n_i <- combos$N[i]
  c_i <- combos$C[i]
  dat <- subset(pred_df, N == n_i & C == c_i)
  if (nrow(dat) == 0) next

  p <- ggplot()

  # add appropriate null model
  null_data <- if (c_i == 1) null_dataC1 else if (c_i == 3) null_dataC3 else if (c_i == 5) null_dataC5 else NULL
  
  if (!is.null(null_data)) {
    p <- p +
      geom_ribbon(data = null_data,
                  aes(x = abund, ymin = ci_lower, ymax = ci_upper),
                  alpha = 0.2, fill = "black") +
      geom_line(data = null_data,
                aes(x = abund, y = fitted),
                linetype = "dashed", size = .5, color = "black", alpha = 0.9)
  }

  # CHANGED: treatment lines now colored by NL (specificity)
  p <- p +
    geom_ribbon(data = dat, 
                aes(x = abund, ymin = ci_lower, ymax = ci_upper, fill = NL_fac),
                alpha = 0.1) +
    geom_line(data = dat, 
              aes(x = abund, y = fitted, color = NL_fac), 
              size = 1.2) +
    scale_x_log10(limits = x_range, expand = expansion(mult = 0.02)) +
    labs(title = paste0("strength = ", n_i, ", radius = ", c_i),
         x = "species abundance",
         y = "stabilizing CDD (%)",
         color = "specificity (lambda)",
         fill = "specificity (lambda)") +
    theme_classic(base_size = 16) +
    theme(legend.position = "bottom",
          legend.key.size = unit(0.5, "cm"),
          # legend.text = element_text(size = 10),
          # legend.title = element_text(size = 11),
          plot.title = element_text(size = 14, hjust = 0.5)) +
    scale_color_manual(values = cb_colors) +
    scale_fill_manual(values = cb_colors) +
    coord_cartesian(ylim = c(-0.0004, 0.0010))

  plots_list[[i]] <- p
}

# Print all plots
sapply(plots_list, print)

```

## save PDF

```{r}
# pdf(paste0(root, "local/figures/plot_sr-params/nddSlopeMax.pdf"), width = 6, height = 6, onefile = TRUE, useDingbats = FALSE)
# sapply(plots_list, print)   # each print() â†’ new page
# dev.off()
```

# compare correlation (slope) with max species abundance and SR

```{r}
datmeta <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-PL-P-pDC_datmetaMax.rds"))
metamod <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-PL-P-pDC_metamodMax.rds"))
runs <- readRDS(paste0(root, "local/runs/plot_sr-params/mat/fix-PL-P-pDC.rds"))
```

```{r}

namesShort <- names(datmeta) %>%
  stringr::str_remove("_disp.+") %>% 
  stringr::str_replace("Cut", "-C") %>% 
  stringr::str_replace("Cut", "-C") %>% 
  stringr::str_replace("pdd", "P") %>% 
  stringr::str_replace("ndd", "N") %>% 
  stringr::str_replace_all("Var", "-L")


pred <- lapply(datmeta, function(x){
  expand_grid(log_N = seq(min(x$log_N, na.rm = TRUE),
                          max(x$log_N, na.rm = TRUE),
                          length.out = 1000))
})
pred <- lapply(pred, function(x){
  x$abund <- exp(x$log_N)
  x
})
pred <- lapply(seq_along(pred), function(i){
  x <- pred[[i]]
  y <- metamod[[i]]
  cbind(x, predict(object = y, newmods = x$log_N))
})
names(pred) <- namesShort   # <- your vector like the one you listed

## --- helper: parse N, NL, C from the *second* chunk (ignore P-part) ---
extract_params <- function(nm) {
  # expect "P1-L5-C1_N0.2-L10-C3"
  rhs <- sub(".*_", "", nm)                 # "N0.2-L10-C3"
  N  <- as.numeric(sub("N([0-9.]+).*", "\\1", rhs))
  NL <- as.numeric(sub(".*-L([0-9.]+).*", "\\1", rhs))
  C  <- as.numeric(sub(".*-C([0-9.]+)$",   "\\1", rhs))
  data.frame(N = N, NL = NL, C = C)
}

## --- bind list to df with parsed params ---
pred_df_raw <- do.call(rbind, lapply(seq_along(pred), function(i) {
  df <- pred[[i]]
  pars <- extract_params(names(pred)[i])
  df$scenario <- names(pred)[i]
  df$N  <- pars$N
  df$NL <- pars$NL
  df$C  <- pars$C
  df
}))


# get slopes
slope <- sapply(metamod, function(x){
  ret <- coef(x)[2]
  return(ret)
})
res <- as.data.frame(slope)
rownames(res) <- names(metamod)

# get intercept
int <- sapply(metamod, function(x){
  ret <- coef(x)[1]
  return(int = ret)
})
int <- data.frame(
  param = names(metamod),
  int = int
)

# get abundance: use max to exclude extremely high values
abund <- sapply(datmeta, function(x){
  return(max(x = x$abund))
})
abund <- data.frame(
  param = names(datmeta),
  abund = abund
)

# get CV of each scenario
cv <- sapply(pred, function(x){
  c(meanMC = mean(x$pred), sdMC = sd(x$pred), rangeMC = diff(range(x$pred)))
}) %>%
  t() %>%
  as.data.frame() %>%
  mutate(cvMC = sdMC / meanMC) %>%
  rownames_to_column("param")

# get sr and rename
srRaw <- getSpecTime(runs, plot = FALSE)
sr <- sapply(srRaw, function(x) {
  vals <- x$spec_rich[99:200]
  c(meanSR = mean(vals), sdSR = sd(vals), medianSR = median(vals))
}) %>% t() %>% as.data.frame()
rownames(sr) <- names(metamod)

# combine all results
res <- res %>% 
  rownames_to_column("param") %>% 
  left_join(
    sr %>% 
      rownames_to_column("param"),
    by = "param"
  ) %>% 
  left_join(
    abund, by = "param"
  ) %>% 
  left_join(
    int, by = "param"
  ) %>% 
  mutate(medianSR = as.integer(medianSR),
         abund = as.integer(abund)) %>% 
  left_join(cv, by = "param")

# filter by scenarios
resC1 <- res %>%
  dplyr::filter(grepl("_N.*-C1$", param))
resC3 <- res %>%
  dplyr::filter(grepl("_N.*-C3$", param))
resC5 <- res %>%
  dplyr::filter(grepl("_N.*-C5$", param))
```

```{r}
#| fig-width: 10
#| fig-height: 6.5

## ---- helper functions ----
pred_glm_pois <- function(mod, newdata, k = 2) {
  lp <- predict(mod, newdata = newdata, se.fit = TRUE, type = "link")
  fit <- exp(lp$fit)
  lo  <- exp(lp$fit - k*lp$se.fit)
  hi  <- exp(lp$fit + k*lp$se.fit)
  list(fit = fit, lo = lo, hi = hi)
}

# Helper function to format p-values
format_pvalue <- function(p) {
  if (p < 0.001) {
    return("p < 0.001")
  } else if (p < 0.01) {
    return(sprintf("p = %.3f", p))
  } else {
    return(sprintf("p = %.2f", p))
  }
}

# Unified function for species richness vs slope plot
plot_sr_slope <- function(dat, tag, ylim_sr = c(40,100)) {
  fm1 <- lm(meanSR ~ slope, data = dat)
  newdat <- data.frame(slope = seq(min(dat$slope), max(dat$slope), length = 100))
  predi <- predict(fm1, newdata = newdat, se.fit = TRUE)
  
  # Extract p-value
  p_val <- summary(fm1)$coefficients[2, 4]  # p-value for slope coefficient
  p_text <- format_pvalue(p_val)
  
  plot(dat$slope, dat$meanSR, ylim = ylim_sr, pch = 16, col = "blue",
       xlab = "mortality change ~ abundance: slope", ylab = "mean species richness",
       main = paste0("Species Richness - Scenario ", tag))
  points(dat$slope, dat$medianSR, pch = 16, col = "red")
  arrows(dat$slope, dat$meanSR - dat$sdSR, dat$slope, dat$meanSR + dat$sdSR,
         angle = 90, code = 3, length = 0.05)
  lines(newdat$slope, predi$fit, lwd = 2, col = 1)
  lines(newdat$slope, predi$fit - 2*predi$se.fit, lwd = 1, lty = 2, col = 1)
  lines(newdat$slope, predi$fit + 2*predi$se.fit, lwd = 1, lty = 2, col = 1)
  legend("topright", legend = c("mean SR", "median SR", "fitted lm", "CI"),
         pch = c(16,16,NA,NA), lty = c(NA,NA,1,2), col = c(4,2,1,1), bty = "n")
  
  # Add p-value text
  text(x = par("usr")[1] + 0.02 * diff(par("usr")[1:2]), 
       y = par("usr")[4] - 0.05 * diff(par("usr")[3:4]), 
       labels = p_text, pos = 4, cex = 0.9, col = "darkred")
}

# Unified function for abundance vs slope plot
plot_abund_slope <- function(dat, tag, ylim_abund = NULL) {
  fm2 <- glm(abund ~ slope, data = dat, family = poisson())
  newdat <- data.frame(slope = seq(min(dat$slope), max(dat$slope), length = 100))
  pg <- pred_glm_pois(fm2, newdat, k = 2)
  
  # Extract p-value
  p_val <- summary(fm2)$coefficients[2, 4]  # p-value for slope coefficient
  p_text <- format_pvalue(p_val)
  
  plot(dat$slope, dat$abund, pch = 16, col = 1,
       xlab = "mortality change ~ abundance: slope", ylab = "max abundance",
       main = paste0("Abundance - Scenario ", tag), ylim = ylim_abund)
  lines(newdat$slope, pg$fit, lwd = 2, col = 1)
  lines(newdat$slope, pg$lo, lwd = 1, lty = 2, col = 1)
  lines(newdat$slope, pg$hi, lwd = 1, lty = 2, col = "grey")
  legend("topleft", legend = c("abund", "fitted glm pois", "CI"),
         pch = c(16,NA,NA), lty = c(NA,1,2), col = c(1,1,1), bty = "n")
  
  # Add p-value text
  text(x = par("usr")[1] + 0.75 * diff(par("usr")[1:2]), 
       y = par("usr")[4] - 0.05 * diff(par("usr")[3:4]), 
       labels = p_text, pos = 4, cex = 0.9, col = "darkred")
}

# Unified function for species richness vs CV mortality change
plot_sr_cvmc <- function(dat, tag, ylim_sr = c(40,90)) {
  fm3 <- lm(meanSR ~ cvMC, data = dat)
  newdat <- data.frame(cvMC = seq(min(dat$cvMC), max(dat$cvMC), length = 100))
  pred <- predict(fm3, newdata = newdat, se.fit = TRUE)
  
  # Extract p-value
  p_val <- summary(fm3)$coefficients[2, 4]  # p-value for cvMC coefficient
  p_text <- format_pvalue(p_val)
  
  cols <- viridis(length(dat$slope))[rank(dat$slope)]
  plot(dat$cvMC, dat$meanSR, ylim = ylim_sr, pch = 16, col = cols,
       xlab = "CV Mortality Change", ylab = "mean species richness",
       main = paste0("SR vs CV MC - Scenario ", tag))
  arrows(dat$cvMC, dat$meanSR - dat$sdSR, dat$cvMC, dat$meanSR + dat$sdSR,
         angle = 90, code = 3, length = 0.05, col = cols)
  lines(newdat$cvMC, pred$fit, lwd = 2, col = 1)
  lines(newdat$cvMC, pred$fit - 2*pred$se.fit, lwd = 1, lty = 2, col = 1)
  lines(newdat$cvMC, pred$fit + 2*pred$se.fit, lwd = 1, lty = 2, col = 1)
  legend("topright", title = "slope",
         fill = viridis(5),
         legend = signif(seq(min(dat$slope), max(dat$slope), length.out = 5), 2),
         bty = "n")
  
  # Add p-value text
  text(x = par("usr")[1] + 0.02 * diff(par("usr")[1:2]), 
       y = par("usr")[4] - 0.05 * diff(par("usr")[3:4]), 
       labels = p_text, pos = 4, cex = 0.9, col = "darkred")
}

# Unified function for species richness vs mean mortality change
plot_sr_meanmc <- function(dat, tag, ylim_sr = c(40,90)) {
  fm4 <- lm(meanSR ~ log(meanMC), data = dat)
  newdat <- data.frame(meanMC = seq(min(dat$meanMC), max(dat$meanMC), length = 100))
  pred <- predict(fm4, newdata = newdat, se.fit = TRUE)
  
  # Extract p-value
  p_val <- summary(fm4)$coefficients[2, 4]  # p-value for log(meanMC) coefficient
  p_text <- format_pvalue(p_val)
  
  cols <- viridis(length(dat$slope))[rank(dat$slope)]
  plot(dat$meanMC, dat$meanSR, ylim = ylim_sr, pch = 16, col = cols,
       xlab = "mean Mortality Change", ylab = "mean species richness",
       main = paste0("SR vs Mean MC - Scenario ", tag))
  lines(newdat$meanMC, pred$fit, lwd = 2, col = 1)
  lines(newdat$meanMC, pred$fit - 2*pred$se.fit, lwd = 1, lty = 2, col = 1)
  lines(newdat$meanMC, pred$fit + 2*pred$se.fit, lwd = 1, lty = 2, col = 1)
  legend("bottomright", title = "slope",
         fill = viridis(5),
         legend = signif(seq(min(dat$slope), max(dat$slope), length.out = 5), 2),
         bty = "n")
  legend("topleft", legend = c("fitted lm log(meanMC)", "CI"),
         lty = c(1,2), bty = "n")
  
  # Add p-value text
  text(x = par("usr")[1] + 0.75 * diff(par("usr")[1:2]), 
       y = par("usr")[4] - 0.05 * diff(par("usr")[3:4]), 
       labels = p_text, pos = 4, cex = 0.9, col = "darkred")
}


# Master plotting function for all scenario plots (6 plot types per scenario)
plot_all_scenarios <- function(scenario_list, scenario_names, 
                              ylim_sr = c(40,100), ylim_abund = c(0,15000)) {
  n_scenarios <- length(scenario_list)
  
  # For each scenario, create all 6 plot types
  for(i in 1:n_scenarios) {
    # Set up 2x3 grid for each scenario
    par(mfrow = c(2, 3), mar = c(4,4,3,2))
    
    cat("Plotting scenario", scenario_names[i], "\n")
    
    # Main analysis plots
    plot_sr_slope(scenario_list[[i]], scenario_names[i], ylim_sr)
    plot_abund_slope(scenario_list[[i]], scenario_names[i], ylim_abund)
    plot_sr_cvmc(scenario_list[[i]], scenario_names[i], ylim_sr)
    plot_sr_meanmc(scenario_list[[i]], scenario_names[i], ylim_sr)
    
    # Additional diagnostic plots with models and p-values
    cols <- viridis(length(scenario_list[[i]]$slope))[rank(scenario_list[[i]]$slope)]
    
    # Diagnostic 1: SD MC vs slope (with linear model and p-value)
    fm_diag1 <- lm(slope ~ sdMC, data = scenario_list[[i]])
    p_val1 <- summary(fm_diag1)$coefficients[2, 4]
    p_text1 <- format_pvalue(p_val1)
    
    plot(scenario_list[[i]]$sdMC, scenario_list[[i]]$slope, pch = 16, 
         xlab = "SD Mortality Change", ylab = "slope",
         main = paste0("SD MC vs Slope - Scenario ", scenario_names[i]))
    abline(fm_diag1, col = "black", lwd = 2)
    text(x = par("usr")[1] + 0.75 * diff(par("usr")[1:2]), 
         y = par("usr")[4] - 0.05 * diff(par("usr")[3:4]), 
         labels = p_text1, pos = 4, cex = 0.9, col = "darkred")
    
    # Diagnostic 2: SD MC vs meanSR (colored by slope, with linear model and p-value)
    fm_diag2 <- lm(meanSR ~ sdMC, data = scenario_list[[i]])
    p_val2 <- summary(fm_diag2)$coefficients[2, 4]
    p_text2 <- format_pvalue(p_val2)
    
    plot(scenario_list[[i]]$sdMC, scenario_list[[i]]$meanSR, pch = 16, col = cols,
         xlab = "SD Mortality Change", ylab = "mean species richness",
         main = paste0("SD MC vs SR - Scenario ", scenario_names[i]), ylim = c(45,85))
    abline(fm_diag2, col = "black", lwd = 2)
    legend("bottomright", title = "slope", fill = viridis(5),
           legend = signif(seq(min(scenario_list[[i]]$slope), max(scenario_list[[i]]$slope), length.out = 5), 2), bty = "n")
    text(x = par("usr")[1] + 0.02 * diff(par("usr")[1:2]), 
         y = par("usr")[4] - 0.05 * diff(par("usr")[3:4]), 
         labels = p_text2, pos = 4, cex = 0.9, col = "darkred")
  }
}

## ---- apply to scenarios C1-C5 ----
# Assuming you have data objects: resC1, resC2, resC3, resC4, resC5
scenario_data <- list(resC1, resC3, resC5)
scenario_labels <- c("C1", "C3", "C5")


# pdf(paste0(root, "local/figures/plot_sr-params/nddSupplPlots.pdf"), width = 10, height = 6.5, onefile = TRUE, useDingbats = FALSE)
    # Generate all plots for all scenarios with p-values
    plot_all_scenarios(scenario_data, scenario_labels, 
                       ylim_sr = c(40,100), ylim_abund = c(0,15000))
    plot_all_scenarios(list(res), "all_data", 
                       ylim_sr = c(40,100), ylim_abund = c(0,15000))
# dev.off()

```

```{r}
#| fig-width: 10
#| fig-height: 5

# Parse the param column to extract N, NL, and C values
res_parsed <- res %>%
  # Split the param column at the underscore to get the two parts
  separate(param, into = c("part1", "part2"), sep = "_", remove = FALSE) %>%
  # Extract N, NL, C from first part (P1-L5-C1 format)
  extract(part1, into = c("P1", "L1", "C1"), regex = "P([0-9]+)-L([0-9.]+)-C([0-9]+)", remove = FALSE) %>%
  # Extract N, NL, C from second part (N0-L20-C1 format)
  extract(part2, into = c("N", "NL", "C"), regex = "N([0-9.]+)-L([0-9.]+)-C([0-9]+)", remove = FALSE) %>%
  # Convert to numeric
  mutate(
    N = as.numeric(N),
    NL = as.numeric(NL),
    C = as.numeric(C)
  ) #%>%
  # Remove the temporary columns we don't need
  # select(-part1, -part2, -P1, -L1, -C1)

# Check the parsed data
print("Parsed data structure:")
print(head(res_parsed))

# Get the N=0 baseline (assuming it exists for NL=20)
base0 <- res_parsed %>% filter(N == 0, NL == 20)

# All NL values present in the data
all_NL <- sort(unique(res_parsed$NL))

# For each C value, replicate the N=0 point across all NL values if needed
if(nrow(base0) > 0) {
  base0_expanded <- do.call(rbind, lapply(unique(base0$C), function(c_val) {
    base_c <- base0[base0$C == c_val, ]
    expanded <- base_c[rep(1, length(all_NL)), ]
    expanded$NL <- all_NL
    return(expanded)
  }))
  
  # Remove the original N=0, NL=20 entries to avoid duplicates
  res_filtered <- res_parsed %>% filter(!(N == 0 & NL == 20))
  
  # Bind expanded baseline back
  res_final <- bind_rows(res_filtered, base0_expanded) %>% 
    mutate(sdMC = case_when(
      N == 0 & NL != 20 ~ sdMC,
      TRUE ~ sdMC
    ))
} else {
  # If no N=0 baseline exists, use the original data
  res_final <- res_parsed
}

# Create the baseline point for each C value (if they exist)
baseline_unique <- res_final %>% 
  filter(N == 0) %>%
  group_by(C) %>%
  slice(1) %>%
  ungroup()

# Create complete dataset for points (N > 0)
complete_data <- res_final %>% filter(N > 0)

# Create the plot
plotNDD_MC <- ggplot() +
  # Plot lines connecting all points (including baseline)
  geom_line(data = res_final, 
            aes(x = N, y = meanMC, color = factor(NL), group = NL), 
            size = 0.8) +
  # Plot colored points for N > 0
  geom_point(data = complete_data, 
             aes(x = N, y = meanMC, color = factor(NL)), 
             size = 2, position = position_dodge(width = 0.075)) +
  geom_errorbar(data = complete_data,
                aes(x = N, y = meanMC, color = factor(NL),
                    ymin = meanMC - sdMC, ymax = meanMC + sdMC),
                width = 0.05, alpha = .5, size = .75,
                position = position_dodge(width = 0.075)) +
  # Add baseline points if they exist
  {if(nrow(baseline_unique) > 0) {
    list(
      geom_point(data = baseline_unique, 
                 aes(x = N, y = meanMC), 
                 color = "black", size = 4, shape = 3),
      geom_errorbar(data = baseline_unique,
                    aes(x = N, y = meanMC, ymin = meanMC - sdMC, ymax = meanMC + sdMC),
                    color = "black", width = 0.005, alpha = 1)
    )
  }} +
  facet_wrap(~ C, ncol = 3, scales = "fixed",
             labeller = labeller(C = function(x) paste("radius =", x))) +
  labs(x = "strength",
       y = "mean stabilizing CDD (%)",
       color = "lambda\n(specificity)") +
  theme_classic(base_size = 16) +
  theme(
    strip.background = element_blank(),
    legend.position = "right",
    strip.text = element_text(size = 15, margin = margin(b = -0)),
    plot.margin = margin(20, 20, 20, 20),
    panel.spacing = unit(1, "lines"),
    axis.title.x = element_text(margin = margin(t = 15)),
    axis.title.y = element_text(margin = margin(r = 15)),
    panel.grid.major.y = element_line(color = "grey90", size = 0.2),
    panel.grid.minor.y = element_line(color = "grey95", size = 0.2),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) + 
  coord_cartesian(clip = "off") +
  scale_color_manual(values = cb_colors) +
  scale_x_continuous(breaks = seq(0, 1, by = 0.2)) + 
    geom_hline(
    data = baseline_unique,
    aes(yintercept = meanMC),
    linetype = "dashed",
    color = "black"
  )

print(plotNDD_MC)

```

```{r}
pdf(paste0(root, "local/figures/plot_sr-params/nddEffectOnMC.pdf"), width = 10, height = 5, onefile = TRUE, useDingbats = FALSE)
print(plotNDD_MC)
dev.off()
```

```{r}
cb_colors <- c(
  "#029E73",  # Green
  "#0173B2",  # Blue
  "#DE8F05",  # Orange
  "#CC78BC",  # Purple
  "firebrick"   # Brown
)
```

```{r}
#| fig-width: 10
#| fig-height: 5

# Parse the param column to extract N, NL, and C values
res_parsed <- res %>%
  # Split the param column at the underscore to get the two parts
  separate(param, into = c("part1", "part2"), sep = "_", remove = FALSE) %>%
  # Extract N, NL, C from first part (P1-L5-C1 format)
  extract(part1, into = c("P1", "L1", "C1"), regex = "P([0-9]+)-L([0-9]+)-C([0-9]+)", remove = FALSE) %>%
  # Extract N, NL, C from second part (N0-L20-C1 format)
  extract(part2, into = c("N", "NL", "C"), regex = "N([0-9.]+)-L([0-9.]+)-C([0-9]+)", remove = FALSE) %>%
  # Convert to numeric
  mutate(
    N = as.numeric(N),
    NL = as.numeric(NL),
    C = as.numeric(C)
  ) #%>%
  # Remove the temporary columns we don't need
  # select(-part1, -part2, -P1, -L1, -C1)

# Check the parsed data
print("Parsed data structure:")
print(head(res_parsed))

# Get the N=0 baseline (assuming it exists for NL=20)
base0 <- res_parsed %>% filter(N == 0, NL == 20)

# All NL values present in the data
all_NL <- sort(unique(res_parsed$NL))

# For each C value, replicate the N=0 point across all NL values if needed
if(nrow(base0) > 0) {
  base0_expanded <- do.call(rbind, lapply(unique(base0$C), function(c_val) {
    base_c <- base0[base0$C == c_val, ]
    expanded <- base_c[rep(1, length(all_NL)), ]
    expanded$NL <- all_NL
    return(expanded)
  }))
  
  # Remove the original N=0, NL=20 entries to avoid duplicates
  res_filtered <- res_parsed %>% filter(!(N == 0 & NL == 20))
  
  # Bind expanded baseline back
  res_final <- bind_rows(res_filtered, base0_expanded) %>% 
    mutate(sdSR = case_when(
      N == 0 & NL != 20 ~ sdSR,
      TRUE ~ sdSR
    ))
} else {
  # If no N=0 baseline exists, use the original data
  res_final <- res_parsed
}

# Create the baseline point for each C value (if they exist)
baseline_unique <- res_final %>% 
  filter(N == 0) %>%
  group_by(C) %>%
  slice(1) %>%
  ungroup()

# Create complete dataset for points (N > 0)
complete_data <- res_final %>% filter(N > 0)

# Create the plot
plotNDD_SR <- ggplot() +
  # Plot lines connecting all points (including baseline)
  geom_line(data = res_final, 
            aes(x = N, y = meanSR, color = factor(NL), group = NL), 
            size = 0.8) +
  # Plot colored points for N > 0
  geom_point(data = complete_data, 
             aes(x = N, y = meanSR, color = factor(NL)), 
             size = 2, position = position_dodge(width = 0.075)) +
  geom_errorbar(data = complete_data,
                aes(x = N, y = meanSR, color = factor(NL),
                    ymin = meanSR - sdSR, ymax = meanSR + sdSR),
                width = 0.05, alpha = .5, size = .75,
                position = position_dodge(width = 0.075)) +
  # Add baseline points if they exist
  {if(nrow(baseline_unique) > 0) {
    list(
      geom_point(data = baseline_unique, 
                 aes(x = N, y = meanSR), 
                 color = "black", size = 4, shape = 3),
      geom_errorbar(data = baseline_unique,
                    aes(x = N, y = meanSR, ymin = meanSR - sdSR, ymax = meanSR + sdSR),
                    color = "black", width = 0.005, alpha = 1)
    )
  }} +
  facet_wrap(~ C, ncol = 3, scales = "fixed",
             labeller = labeller(C = function(x) paste("radius =", x))) +
  labs(x = "strength",
       y = "mean species richness",
       color = "lambda\n(specificity)") +
  theme_classic(base_size = 16) +
  theme(
    strip.background = element_blank(),
    legend.position = "right",
    strip.text = element_text(size = 15, margin = margin(b = -20)),
    plot.margin = margin(20, 20, 20, 20),
    panel.spacing = unit(1, "lines"),
    axis.title.x = element_text(margin = margin(t = 15)),
    axis.title.y = element_text(margin = margin(r = 15)),
    panel.grid.major.y = element_line(color = "grey90", size = 0.2),
    panel.grid.minor.y = element_line(color = "grey95", size = 0.2),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) + 
  coord_cartesian(clip = "off") +
  scale_color_manual(values = cb_colors) +
  scale_x_continuous(breaks = seq(0, 1, by = 0.2)) 

print(plotNDD_SR)

```

```{r}
pdf(paste0(root, "local/figures/plot_sr-params/nddEffectOnSR.pdf"), width = 10, height = 5, onefile = TRUE, useDingbats = FALSE)
print(plotNDD_SR)
dev.off()
```
