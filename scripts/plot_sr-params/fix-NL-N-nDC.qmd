---
title: "PhyloSim Changes"
author: "A.I."
format:
  html:
    number-sections: true
editor: visual
---

```{r}
#| warning: false
library(PhyloSim)
library(parallel)
library(dplyr)
library(tidyverse)
library(lattice)
library(ggplot2)
library(metafor)
library(MASS)
library(viridis)
# root <- "~/Uni/Master/MA/" # work from local machine
root <- "~/cyber_synch/" # work from uni bayreuth server
```

**Here, I plot the effects of N, NL, nDC while all P properties are fixed**

## Data preparation

```{r}
#| eval: false

# load in runs with exp kernel
runsRaw  <- readRDS(paste0(root, "/local/runs/plot_sr-params/mat/fix-N-NL-nDC.rds"))
```

```{r}
#| eval: false

# get conspecific neighbors and proper naming
runsRaw  <- getConNeigh(runsRaw, radius = 5)
```

```{r}
# saveRDS(runsRaw, paste0(root, "/local/runs/plot_sr-params/temp/fix-NL-N-nDC_conMax.rds"))
# runsRaw  <- readRDS(paste0(root, "/local/runs/plot_sr-params/temp/fix-NL-N-nDC_conMax.rds"))
```

```{r}
# make the runs more slim
# runs_ix <- lapply(runsRaw, function(x){
#   x$Output <- x$Output[101:300]
#   return(x)
# })
```

```{r}
namesShort <- names(runsRaw) %>%
  stringr::str_remove("_disp.+") %>% 
  stringr::str_replace("Cut", "-C") %>% 
  stringr::str_replace("Cut", "-C") %>% 
  stringr::str_replace("pdd", "P") %>% 
  stringr::str_replace("ndd", "N") %>% 
  stringr::str_replace_all("Var", "-L")

```

```{r}
names(runsRaw) <- namesShort
```

```{r}
S <- getSpecTime(runsRaw, plot = FALSE)
```

```{r}
# Extract species richness data
Sp <- sapply(S, function(x){
  return(c(mean(x$spec_rich[99:200]), sd(x$spec_rich[99:200])))
}) %>% t() %>% as.data.frame()
colnames(Sp) <- c("meanSR", "sdSR")
Sp$params <- namesShort 

# Parse parameters correctly
Sp2 <- Sp %>%
  extract(params,
          into = c("P","PL","C"),
          regex = "P([0-9.]+)-L([0-9.]+)-C([0-9]+)",
          remove = FALSE) %>%
  mutate(P = as.numeric(P),
         PL = as.numeric(PL),
         C = as.numeric(C))

# Get the P=0 baseline (only exists for PL=20)
base0 <- Sp2 %>% filter(P == 0, PL == 20)

# Get all unique PL values present in the data
all_PL <- sort(unique(Sp2$PL))

# For each C value, replicate the P=0 point for all PL values
base0_expanded <- do.call(rbind, lapply(unique(base0$C), function(c_val) {
  base_c <- base0[base0$C == c_val, ]
  # Replicate for each PL value
  expanded <- base_c[rep(1, length(all_PL)), ]
  expanded$PL <- all_PL
  expanded$params <- paste0("P0-L", all_PL, "-C", c_val, "_N1-L5-C1")
  return(expanded)
}))

# Remove the original P=0, PL=20 entries to avoid duplicates
Sp2_filtered <- Sp2 %>% filter(!(P == 0 & PL == 20))

# Bind the expanded baseline back
Sp2_final <- bind_rows(Sp2_filtered, base0_expanded) %>% 
  mutate(sdSR = case_when(
    P == 0 & PL != 20 ~ NA_real_,
    TRUE ~ sdSR,
  ))
```

```{r}
#| fig-width: 10
#| fig-height: 3.5

# Create the plot
plotPDD <- ggplot(Sp2_final, aes(x = P, y = meanSR, color = factor(PL), group = PL)) +
  geom_line(size = .8) +
geom_point(size = 2, position = position_dodge(width = 0.1)) +
geom_errorbar(
  aes(ymin = meanSR - sdSR, ymax = meanSR + sdSR),
  width = 0.05,
  alpha = 1,
  position = position_dodge(width = 0.1)
) +
  facet_wrap(~ C, ncol = 3, scales = "fixed",
             labeller = labeller(C = function(x) paste("pDD kernel =", x))) +
  labs(x = "pDD strength",
       y = "mean species richness",
       color = "pDD\nspecificity") +
  theme_classic(base_size = 16) +
  theme(
    strip.background = element_blank(),
    legend.position = "right",
    strip.text = element_text(size = 15),
    panel.spacing = unit(1, "lines"),
    axis.title.x = element_text(margin = margin(t = 15)),  # move x-label down
    axis.title.y = element_text(margin = margin(r = 15))   # move y-label left
  )

print(plotPDD)
```

```{r}
# pdf(paste0(root, "local/figures/plot_sr-params/pddEffect.pdf"), width = 10, height = 3.5, onefile = TRUE, useDingbats = FALSE)
print(plotPDD)
dev.off()
```

Next, we convert the matrix data into tabular data. With the argument detailedParams we include the parameter settings a seperate cols. We save the tabular data.

```{r}
#| eval: false


# reduce size of data by burn in period until equilibrium is reached
runsFilt <- lapply(runsRaw, function(x){
  x$Output <- x$Output[99:200]
  x$Model$runs <- x$Model$runs[99:200]
  return(x)
})

# convert matrices to tabular data. This is done parallel, as it takes longer
cl <- makeCluster(39)
clusterExport(cl, c("getMatToTab", "runsFilt"))
tab <- parLapply(cl = cl, X = runsFilt, fun = function(x) getMatToTab(x, detailedParams = TRUE))
stopCluster(cl)

# saveRDS(tab, paste0(root, "local/runs/plot_sr-params/tab/fix-N-NL-nDCMax.rds"))
```

```{r}
# tab <- readRDS(paste0(root, "local/runs/plot_sr-params/tab/fix-PL-P-pDC.rds"))
```

```{r}
# keep only first timespot in census

cores <- length(tab)/2
cl <- makeCluster(cores)

clusterEvalQ(cl, {
  library(dplyr)
})

tabS <- parLapply(cl, tab, function(x) {
  x %>%
    filter(abund > 100) %>%
    mutate(specIdCen = paste0(specId, census)) %>%
    select(-indId)
})

stopCluster(cl)
```

### Metafor analysis: correcting for uncertainty

```{r}
#| eval: false

cl <- makeCluster(length(tabS)/2)

mcS_err <- parLapply(cl, tabS, function(x) {
  specIDs <- unique(x$specIdCen)
  res <- vector("list", length(specIDs))
  
  i <- 1
  for (sID in specIDs) {
    dat <- x[x$specIdCen == sID, ]
    mod <- glm(mortNextGen ~ con, data = dat, family = binomial())
    sfm <- summary(mod)$coefficients
    vc <- vcov(mod)[c("(Intercept)", "con"), c("(Intercept)", "con")]

    mort0 <- plogis(coef(mod)[1])
    mort1 <- plogis(coef(mod)[1] + coef(mod)[2])
    
    res[[i]] <- list(
      specId = sID,
      abund = dat$abund[1],
      mort_change = mort1 - mort0,
      coef = coef(mod)[c(1,2)],
      vcov = vc
    )
    i <- i + 1
  }
  return(res)
})

# Stop the cluster
stopCluster(cl)
```

## compute variance of the marginal effect through a "posterior" simulation

```{r}
#| eval: false

cl <- makeCluster(length(mcS_err))
mcS_err_sim <- parLapply(cl, mcS_err, function(x){
  lapply(x, function(y){
    sim <- MASS::mvrnorm(n = 100, mu = c(y$coef[1], y$coef[2]), Sigma = y$vcov)
    mort0 <- plogis(sim[, 1])
    mort1 <- plogis(sim[, 1] + sim[, 2])
    mort_diff <- mort1 - mort0
    
    return(data.frame(
      abund = y$abund,
      specId = y$specId,
      mean = mean(mort_diff),
      se = sd(mort_diff),
      ci_low = quantile(mort_diff, 0.025),
      ci_high = quantile(mort_diff, 0.975)
    ))
  })
})
# Stop the cluster
stopCluster(cl)
```

## unlist inner lists and add log abund

```{r}
#| eval: false

m4 <- lapply(mcS_err_sim, function(group) {
  do.call(rbind, group)
})

m4 <- lapply(m4, function(group) {
  row.names(group) <- NULL
  group <- group %>% 
    mutate(log_N = log(abund))
  return(group)
})
```

## fitting model

```{r}
#| eval: false

dat_meta <- lapply(m4, function(x) {
  escalc(measure = "GEN", yi = mean, sei = se, slab = specId, data = x)
})
```

```{r}
#| eval: false

# # Detect available cores and create a cluster
# cl <- makeCluster(length(dat_meta))
# 
# # Export needed objects and packages to the workers
# clusterExport(cl, varlist = c("dat_meta"), envir = environment())
# 
# # Run in parallel
# metamod <- parLapply(cl, dat_meta, function(x) {
#   metafor::rma(
#     yi = yi,
#     vi = vi,
#     mods = ~ log_N,
#     method = "REML",
#     data = x
#   )
# })
# 
# # Stop cluster
# stopCluster(cl)
# 
# names(metamod) <- namesShort
```

```{r}
cl <- makeCluster(length(dat_meta)/2)
clusterExport(cl, varlist = c("dat_meta"), envir = environment())

metamod <- parLapply(cl, dat_meta, function(x) {
  tryCatch({
    metafor::rma(
      yi = yi,
      vi = vi,
      mods = ~ log_N,
      method = "REML",
      data = x
    )
  }, error = function(e) {
    return(NULL)  # Return NULL for failed models
  })
})

stopCluster(cl)

# Remove NULL elements and keep names aligned
failed_indices <- sapply(metamod, is.null)
namesShort <- names(metamod)
metamod <- metamod[!failed_indices]
names(metamod) <- namesShort[!failed_indices]

# Report which models failed
if(any(failed_indices)) {
  cat("Failed models:", paste(namesShort[failed_indices], collapse = ", "), "\n")
}
```

```{r}

# deleting one scenario

# saveRDS(dat_meta, paste0(root, "local/runs/plot_sr-params/metafor/fix-N-NL-nDC_datmetaMax.rds"))
# saveRDS(metamod, paste0(root, "local/runs/plot_sr-params/metafor/fix-N-NL-nDC_metamodMax.rds"))


metamod <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-N-NL-nDC_metamodMax.rds"))
dat_meta <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-N-NL-nDC_datmetaMax.rds"))
namesShort <- names(metamod)

```

## predictions

### log_N

```{r}
#| fig-width: 6
#| fig-height: 6


cb_colors <- c(
  "#029E73",  # Green
  "#0173B2",  # Blue
  "#DE8F05",  # Orange
  "#CC78BC",  # Purple
  "firebrick"   # Brown
)


## --- build predictions (as you had) ---
pred <- lapply(dat_meta, function(x){
  expand_grid(log_N = seq(min(x$log_N, na.rm = TRUE),
                          max(x$log_N, na.rm = TRUE),
                          length.out = 1000))
})
pred <- lapply(pred, function(x){
  x$abund <- exp(x$log_N)
  x
})
pred <- lapply(seq_along(pred), function(i){
  x <- pred[[i]]
  y <- metamod[[i]]
  cbind(x, predict(object = y, newmods = x$log_N))
})
names(pred) <- namesShort

## --- helper function (unchanged) ---
extract_params <- function(nm) {
  lhs <- sub("_.*", "", nm)
  P  <- as.numeric(sub("P([0-9.]+)-.*", "\\1", lhs))
  PL <- as.numeric(sub(".*-L([0-9.]+)-.*", "\\1", lhs))
  C  <- as.numeric(sub(".*-C([0-9.]+)$", "\\1", lhs))
  data.frame(P = P, PL = PL, C = C)
}

## --- bind list to df with parsed params ---
pred_df_raw <- do.call(rbind, lapply(seq_along(pred), function(i) {
  df <- pred[[i]]
  pars <- extract_params(names(pred)[i])
  df$scenario <- names(pred)[i]
  df$P  <- pars$P
  df$PL <- pars$PL
  df$C  <- pars$C
  df
}))

## --- normalize predict() columns ---
if ("pred" %in% names(pred_df_raw))   names(pred_df_raw)[names(pred_df_raw)=="pred"]   <- "fitted"
if ("fit"  %in% names(pred_df_raw))   names(pred_df_raw)[names(pred_df_raw)=="fit"]    <- "fitted"
if ("ci.lb" %in% names(pred_df_raw))  pred_df_raw$ci_lower <- pred_df_raw$ci.lb
if ("ci.ub" %in% names(pred_df_raw))  pred_df_raw$ci_upper <- pred_df_raw$ci.ub

pred_df <- pred_df_raw %>% filter(P != 0)

## --- null models for each C value ---
null_nameC1 <- "P0-L20-C1_N1-L5-C1"
null_dataC1 <- if (null_nameC1 %in% pred_df_raw$scenario) pred_df_raw[pred_df_raw$scenario == null_nameC1, ] else NULL

null_nameC3 <- "P0-L20-C3_N1-L5-C1"
null_dataC3 <- if (null_nameC3 %in% pred_df_raw$scenario) pred_df_raw[pred_df_raw$scenario == null_nameC3, ] else NULL

null_nameC5 <- "P0-L20-C5_N1-L5-C1"
null_dataC5 <- if (null_nameC5 %in% pred_df_raw$scenario) pred_df_raw[pred_df_raw$scenario == null_nameC5, ] else NULL

## --- CHANGED: build separate plots per (P, C), lines = PL levels ---
library(ggplot2)

# common axes
x_range <- range(pred_df$abund[pred_df$abund > 0 & is.finite(pred_df$abund)], na.rm = TRUE)
y_range <- range(c(pred_df$ci_lower, pred_df$ci_upper), na.rm = TRUE)

# order PL nicely for legend (now PL is color)
pred_df$PL_fac <- factor(pred_df$PL, levels = sort(unique(pred_df$PL)))

# CHANGED: now combinations are P and C
combos <- unique(pred_df[c("P", "C")])
combos <- combos[order(combos$P, combos$C), ]

plots_list <- vector("list", nrow(combos))
names(plots_list) <- paste0("P", combos$P, "_C", combos$C)

for (i in seq_len(nrow(combos))) {
  p_i <- combos$P[i]
  c_i <- combos$C[i]
  dat <- subset(pred_df, P == p_i & C == c_i)
  if (nrow(dat) == 0) next

  p <- ggplot()

  # add appropriate null model
  null_data <- if (c_i == 1) null_dataC1 else if (c_i == 3) null_dataC3 else if (c_i == 5) null_dataC5 else NULL
  
  if (!is.null(null_data)) {
    p <- p +
      geom_ribbon(data = null_data,
                  aes(x = abund, ymin = ci_lower, ymax = ci_upper),
                  alpha = 0.2, fill = "black") +
      geom_line(data = null_data,
                aes(x = abund, y = fitted),
                linetype = "dashed", size = .5, color = "black", alpha = 0.9)
  }

  # CHANGED: treatment lines now colored by PL (specificity)
  p <- p +
    geom_ribbon(data = dat, 
                aes(x = abund, ymin = ci_lower, ymax = ci_upper, fill = PL_fac),
                alpha = 0.1) +
    geom_line(data = dat, 
              aes(x = abund, y = fitted, color = PL_fac), 
              size = 1.2) +
    scale_x_log10(limits = x_range, expand = expansion(mult = 0.02)) +
    labs(title = paste0("pDD strength = ", p_i, ", pDD radius = ", c_i),
         x = "species abundance",
         y = "stabilizing CDD (%)",
         color = "pDD specificity (lambda)",
         fill = "pDD specificity (lambda)") +
    theme_classic(base_size = 14) +
    theme(legend.position = "bottom",
          legend.key.size = unit(0.5, "cm"),
          plot.title = element_text(size = 14, hjust = 0.5)) +
    scale_color_manual(values = cb_colors) +
    scale_fill_manual(values = cb_colors) +  # Add this for ribbon colors
    coord_cartesian(ylim = c(-0.0004, 0.0013)) +
        annotate("text",
             x = 3000, y = 0.001,
             label = "nDD fixed at\nstrength = 1\nlambda = 5\nspatial kernel = 1",
             hjust = 0, vjust = 1,
             size = 4)

  plots_list[[i]] <- p
}

# Print all plots
sapply(plots_list, print)
```

## save PDF

```{r}
# pdf(paste0(root, "local/figures/plot_sr-params/pddSlopeMax.pdf"), width = 6, height = 6, onefile = TRUE, useDingbats = FALSE)
# sapply(plots_list, print)   # each print() → new page
# dev.off()
```

# compare correlation (slope) with max species abundance and SR

```{r}
datmeta <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-N-NL-nDC_datmetaMax.rds"))
dat_meta <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-N-NL-nDC_datmetaMax.rds"))
metamod <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/fix-N-NL-nDC_metamodMax.rds"))
runs <- readRDS(paste0(root, "local/runs/plot_sr-params/mat/fix-N-NL-nDC.rds"))

# load neutral data too
neutSR <- readRDS(paste0(root, "local/runs/plot_sr-params/neutralSR.rds"))
datmetaNeut <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/datmetaNeut.rds"))
metamodNeut <- readRDS(paste0(root, "local/runs/plot_sr-params/metafor/metamodNeut.rds"))
```

```{r}
# append neut data to DD data

datmeta <- c(datmeta, list(datmetaNeut))
metamod <- c(metamod, list(metamodNeut))
```

```{r}
namesShort <- names(datmeta) 
namesShort[length(namesShort)] <- "neutral"

pred <- lapply(datmeta, function(x){
  expand_grid(log_N = seq(min(x$log_N, na.rm = TRUE),
                          max(x$log_N, na.rm = TRUE),
                          length.out = 1000))
})

pred <- lapply(pred, function(x){
  x$abund <- exp(x$log_N)
  x
})

pred <- lapply(seq_along(pred), function(i){
  x <- pred[[i]]
  y <- metamod[[i]]
  cbind(x, predict(object = y, newmods = x$log_N))
})

names(pred) <- namesShort

## --- helper: parse P, PL, C from the *first* chunk (before underscore) ---
extract_params <- function(nm) {
  # expect "P1-L5-C1_N0.2-L10-C3"
  lhs <- sub("_.*", "", nm)                 # "P1-L5-C1"
  P  <- as.numeric(sub("P([0-9.]+).*", "\\1", lhs))
  PL <- as.numeric(sub(".*-L([0-9.]+).*", "\\1", lhs))
  C  <- as.numeric(sub(".*-C([0-9.]+)$",   "\\1", lhs))
  data.frame(P = P, PL = PL, C = C)
}

## --- bind list to df with parsed params ---
pred_df_raw <- do.call(rbind, lapply(seq_along(pred), function(i) {
  df <- pred[[i]]
  pars <- extract_params(names(pred)[i])
  df$scenario <- names(pred)[i]
  df$P  <- pars$P
  df$PL <- pars$PL
  df$C  <- pars$C
  df
}))

# get slopes
slope <- sapply(metamod, function(x){
  ret <- coef(x)[2]
  return(ret)
})
res <- as.data.frame(slope)
rownames(res) <- namesShort

# get intercept
int <- sapply(metamod, function(x){
  ret <- coef(x)[1]
  return(int = ret)
})
int <- data.frame(
  param = namesShort,
  int = int
)

# get abundance: use max to exclude extremely high values
abund <- sapply(datmeta, function(x){
  return(max(x = x$abund))
})
abund <- data.frame(
  param = names(datmeta),
  abund = abund
)

# get CV of each scenario
cv <- sapply(pred, function(x){
  c(meanMC = mean(x$pred), sdMC = sd(x$pred), rangeMC = diff(range(x$pred)))
}) %>%
  t() %>%
  as.data.frame() %>%
  mutate(cvMC = sdMC / meanMC) %>%
  rownames_to_column("param")

# get sr and rename
srRaw <- getSpecTime(runs, plot = FALSE)
sr <- sapply(srRaw, function(x) {
  vals <- x$spec_rich[99:200]
  c(meanSR = mean(vals), sdSR = sd(vals), medianSR = median(vals))
}) %>% t() %>% as.data.frame()
sr <- rbind(sr, c(neutSR$meanSR, neutSR$sdSR, NA))
rownames(sr) <- namesShort

# combine all results
res <- res %>% 
  rownames_to_column("param") %>% 
  left_join(
    sr %>% 
      rownames_to_column("param"),
    by = "param"
  ) %>% 
  left_join(
    abund, by = "param"
  ) %>% 
  left_join(
    int, by = "param"
  ) %>% 
  mutate(medianSR = as.integer(medianSR),
         abund = as.integer(abund)) %>% 
  left_join(cv, by = "param")
rownames(res) <- namesShort
```

```{r}
cb_colors <- c(
  "#029E73",  # Green
  "#0173B2",  # Blue
  "#DE8F05",  # Orange
  "#CC78BC",  # Purple
  "firebrick"   # Brown
)

```

```{r}
#| fig-width: 10
#| fig-height: 5

# Parse the param column to extract P, PL, and C values for pDD analysis
res_parsed <- res %>%
  # Split the param column at the underscore to get the two parts
  separate(param, into = c("part1", "part2"), sep = "_", remove = FALSE) %>%
  # Extract P, PL, C from first part (P1-L5-C1 format) - this is our pDD data
  extract(part1, into = c("P", "PL", "C1"), regex = "P([0-9.]+)-L([0-9.]+)-C([0-9]+)", remove = FALSE) %>%
  # Extract N, NL, C from second part (N0-L20-C1 format) - this should be fixed nDD
  extract(part2, into = c("N", "NL", "C2"), regex = "N([0-9.]+)-L([0-9]+)-C([0-9]+)", remove = FALSE) %>%
  # Convert to numeric
  mutate(
    P = as.numeric(P),
    PL = as.numeric(PL),
    N = as.numeric(N),
    NL = as.numeric(NL),
    C1 = as.numeric(C1),
    C2 = as.numeric(C2)
  ) %>%
  # Use C1 as the main C value (pDD kernel parameter)
  mutate(C = C1)

# Check the parsed data
print("Parsed data structure:")
print(head(res_parsed))

# Get the P=0 baseline (assuming it exists for PL=5 or whatever the baseline PL is)
# First check what PL values exist for P=0
baseline_PL <- unique(res_parsed$PL[res_parsed$P == 0])
print(paste("Available PL values for P=0:", paste(baseline_PL, collapse = ", ")))

# Use the most common PL value for baseline, or the first one if tie
if(length(baseline_PL) > 0) {
  base_PL_val <- baseline_PL[1]  # or use the most appropriate one
  base0 <- res_parsed %>% filter(P == 0, PL == base_PL_val)
} else {
  base0 <- data.frame()  # empty if no P=0 baseline
}

# All PL values present in the data
all_PL <- sort(unique(res_parsed$PL))

# For each C value, replicate the P=0 point across all PL values if needed
if(nrow(base0) > 0) {
  base0_expanded <- do.call(rbind, lapply(unique(base0$C), function(c_val) {
    base_c <- base0[base0$C == c_val, ]
    expanded <- base_c[rep(1, length(all_PL)), ]
    expanded$PL <- all_PL
    return(expanded)
  }))
  
  # Remove the original P=0 entries to avoid duplicates
  res_filtered <- res_parsed %>% filter(!(P == 0 & PL == base_PL_val))
  
  # Bind expanded baseline back
  res_final <- bind_rows(res_filtered, base0_expanded %>% group_by(param) %>% slice(1)) %>% 
    mutate(sdSR = case_when(
      P == 0  ~ sdSR,
      TRUE ~ sdSR
    ))
} else {
  # If no P=0 baseline exists, use the original data
  res_final <- res_parsed
}

# Create the baseline point for each C value (if they exist)
baseline_unique <- res_final %>% 
  filter(P == 0) %>%
  group_by(C) %>%
  slice(1) %>%
  ungroup()

# Create complete dataset for points (P > 0)
complete_data <- res_final %>% filter(P > 0)

# Create the plot
plotPDD_SR <- ggplot() +
  # Plot lines connecting all points (including baseline)
  geom_line(data = res_final, 
            aes(x = P, y = meanSR, color = factor(PL), group = PL), 
            size = 1) +
  # Plot colored points for P > 0
  geom_point(data = complete_data, 
             aes(x = P, y = meanSR, color = factor(PL)), 
             size = 2, position = position_dodge(width = 0.075)) +
  geom_errorbar(data = complete_data,
                aes(x = P, y = meanSR, color = factor(PL),
                    ymin = meanSR - sdSR, ymax = meanSR + sdSR),
                width = 0.05, alpha = .5, size = .75,
                position = position_dodge(width = 0.075)) +
  # Add baseline points if they exist
  {if(nrow(baseline_unique) > 0) {
    list(
      geom_point(data = baseline_unique, 
                 aes(x = P, y = meanSR), 
                 color = "black", size = 4, shape = 3),
      geom_errorbar(data = baseline_unique,
                    aes(x = P, y = meanSR, ymin = meanSR - sdSR, ymax = meanSR + sdSR),
                    color = "black", width = 0.005, alpha = 1)
    )
  }} +
  facet_wrap(~ C, ncol = 3, scales = "fixed",
             labeller = labeller(C = function(x) paste("pDD radius =", x))) +
  labs(x = "pDD strength",
       y = "mean species richness",
       color = "pDD lambda\n(specificity)") +
  theme_classic(base_size = 14) +
  theme(
    strip.background = element_blank(),
    legend.position = "right",
    strip.text = element_text(size = 14, margin = margin(b = -10)),
    plot.margin = margin(20, 20, 20, 20),
    panel.spacing = unit(1, "lines"),
    axis.title.x = element_text(margin = margin(t = 14)),
    axis.title.y = element_text(margin = margin(r = 14)),
    panel.grid.major.y = element_line(color = "grey90", size = 0.2),
    panel.grid.minor.y = element_line(color = "grey95", size = 0.2),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) + 
  coord_cartesian(clip = "off") +
  scale_color_manual(values = cb_colors) +
  scale_x_continuous(breaks = seq(0, 1, by = 0.2)) 
neutSR_df <- data.frame(
  N = 0,                          
  meanSR = neutSR$meanSR,
  sdSR = neutSR$sdSR,
  C = unique(res_final$C)[1],     
  NL = 20                         
)

neutSR_df <- expand.grid(
  N = 0,
  meanSR = neutSR$meanSR,
  sdSR = neutSR$sdSR,
  C = unique(res_final$C),
  NL = 20
)

plotPDD_SR <- plotPDD_SR +
  geom_point(data = neutSR_df,
             aes(x = N, y = meanSR),
             color = "darkgrey", size = 4, shape = 3,
             position = position_nudge(x = 0.02)) +
  geom_errorbar(data = neutSR_df,
                aes(x = N, ymin = meanSR - sdSR, ymax = meanSR + sdSR),
                color = "darkgrey", width = 0.005, size = 0.75,
                position = position_nudge(x = 0.02))

print(plotPDD_SR)

```

```{r}
# pdf(paste0(root, "local/figures/plot_sr-params/pddEffectOnSR.pdf"), width = 10, height = 5, onefile = TRUE, useDingbats = FALSE)
# print(plotPDD_SR)
# dev.off()
```

```{r}
#| fig-width: 10
#| fig-height: 5

# Parse the param column to extract P, PL, and C values for pDD analysis
res_parsed <- res %>%
  # Split the param column at the underscore to get the two parts
  separate(param, into = c("part1", "part2"), sep = "_", remove = FALSE) %>%
  # Extract P, PL, C from first part (P1-L5-C1 format) - this is our pDD data
  extract(part1, into = c("P", "PL", "C1"), regex = "P([0-9.]+)-L([0-9.]+)-C([0-9]+)", remove = FALSE) %>%
  # Extract N, NL, C from second part (N0-L20-C1 format) - this should be fixed nDD
  extract(part2, into = c("N", "NL", "C2"), regex = "N([0-9.]+)-L([0-9.]+)-C([0-9]+)", remove = FALSE) %>%
  # Convert to numeric
  mutate(
    P = as.numeric(P),
    PL = as.numeric(PL),
    N = as.numeric(N),
    NL = as.numeric(NL),
    C1 = as.numeric(C1),
    C2 = as.numeric(C2)
  ) %>%
  # Use C1 as the main C value (pDD kernel parameter)
  mutate(C = C1)

# Check the parsed data
print("Parsed data structure:")
print(head(res_parsed))

# Get the P=0 baseline (assuming it exists for PL=5 or whatever the baseline PL is)
# First check what PL values exist for P=0
baseline_PL <- unique(res_parsed$PL[res_parsed$P == 0])
print(paste("Available PL values for P=0:", paste(baseline_PL, collapse = ", ")))

# Use the most common PL value for baseline, or the first one if tie
if(length(baseline_PL) > 0) {
  base_PL_val <- baseline_PL[1]  # or use the most appropriate one
  base0 <- res_parsed %>% filter(P == 0, PL == base_PL_val)
} else {
  base0 <- data.frame()  # empty if no P=0 baseline
}

# All PL values present in the data
all_PL <- sort(unique(res_parsed$PL))

# For each C value, replicate the P=0 point across all PL values if needed
if(nrow(base0) > 0) {
  base0_expanded <- do.call(rbind, lapply(unique(base0$C), function(c_val) {
    base_c <- base0[base0$C == c_val, ]
    expanded <- base_c[rep(1, length(all_PL)), ]
    expanded$PL <- all_PL
    return(expanded)
  }))
  
  # Remove the original P=0 entries to avoid duplicates
  res_filtered <- res_parsed %>% filter(!(P == 0 & PL == base_PL_val))
  
  # Bind expanded baseline back
  res_final <- bind_rows(res_filtered, base0_expanded) %>% 
    mutate(sdMC = case_when(
      P == 0 & PL != base_PL_val ~ sdMC,
      TRUE ~ sdMC
    ))
} else {
  # If no P=0 baseline exists, use the original data
  res_final <- res_parsed
}

# Create the baseline point for each C value (if they exist)
baseline_unique <- res_final %>% 
  filter(P == 0) %>%
  group_by(C) %>%
  slice(1) %>%
  ungroup()

# Create complete dataset for points (P > 0)
complete_data <- res_final %>% filter(P > 0)

# Create the plot
plotPDD_MC <- ggplot() +
  # Plot lines connecting all points (including baseline)
  geom_line(data = res_final, 
            aes(x = P, y = meanMC, color = factor(PL), group = PL), 
            size = 0.8) +
  # Plot colored points for P > 0
  geom_point(data = complete_data, 
             aes(x = P, y = meanMC, color = factor(PL)), 
             size = 2, position = position_dodge(width = 0.075)) +
  geom_errorbar(data = complete_data,
                aes(x = P, y = meanMC, color = factor(PL),
                    ymin = meanMC - sdMC, ymax = meanMC + sdMC),
                width = 0.05, alpha = .5, size = .75,
                position = position_dodge(width = 0.075)) +
  
  # Add neutral scenario points
  {if(exists("neutMC_df") && nrow(neutMC_df) > 0) {
    list(
      geom_point(data = neutMC_df,
                 aes(x = N, y = meanMC),
                 color = "darkgrey", size = 4, shape = 3,
                  position = position_nudge(x = 0.02)),
      geom_errorbar(data = neutMC_df,
                    aes(x = N, ymin = meanMC - sdMC, ymax = meanMC + sdMC),
                    color = "darkgrey", width = 0.005, size = 0.75,
                     position = position_nudge(x = 0.02))
    )
  }} +
  
  facet_wrap(~ C, ncol = 3, scales = "fixed",
             labeller = labeller(C = function(x) paste("pDD radius =", x))) +
  labs(x = "pDD strength",
       y = "mean stabilizing CDD (%)",
       color = "pDD lambda\n(specificity)") +
  theme_classic(base_size = 14) +
  theme(
    strip.background = element_blank(),
    legend.position = "right",
    strip.text = element_text(size = 14, margin = margin(b = -10)),
    plot.margin = margin(20, 20, 20, 20),
    panel.spacing = unit(1, "lines"),
    axis.title.x = element_text(margin = margin(t = 14)),
    axis.title.y = element_text(margin = margin(r = 14)),
    panel.grid.major.y = element_line(color = "grey90", size = 0.2),
    panel.grid.minor.y = element_line(color = "grey95", size = 0.2),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) + 
    coord_cartesian(clip = "off") +
  scale_color_manual(values = cb_colors) +
  scale_x_continuous(breaks = seq(0, 1, by = 0.2)) + 
    # Add baseline points if they exist
      geom_point(data = baseline_unique, 
                 aes(x = P, y = meanMC), 
                 color = "black", size = 4, shape = 3) +
      geom_errorbar(data = baseline_unique,
                    aes(x = P, y = meanMC, ymin = meanMC - sdMC, ymax = meanMC + sdMC),
                    color = "black", width = 0.005, alpha = 1) 


print(plotPDD_MC)

```

```{r}
# pdf(paste0(root, "local/figures/plot_sr-params/pddEffectOnMC.pdf"), width = 10, height = 5, onefile = TRUE, useDingbats = FALSE)
# print(plotPDD_MC)
# dev.off()
```
