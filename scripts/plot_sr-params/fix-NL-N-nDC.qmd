---
title: "PhyloSim Changes"
author: "A.I."
format:
  html:
    number-sections: true
editor: visual
---

```{r}
#| warning: false
library(PhyloSim)
library(parallel)
library(dplyr)
library(tidyverse)
library(lattice)
library(ggplot2)
library(metafor)
library(MASS)
# root <- "~/Uni/Master/MA/" # work from local machine
root <- "~/cyber_synch/" # work from uni bayreuth server
```

**Here, I plot the effects of N, NL, nDC while all P properties are fixed**

## Data preparation

```{r}
#| eval: false

# load in runs with exp kernel
runsRaw  <- readRDS(paste0(root, "/local/runs/plot_sr-params/mat/fix-NL-N-nDC.rds"))
```

```{r}
#| eval: false

# get conspecific neighbors and proper naming
runsRaw  <- getConNeigh(runsRaw)
```

```{r}
# make the runs more slim
# runs_ix <- lapply(runsRaw, function(x){
#   x$Output <- x$Output[101:300]
#   return(x)
# })
```

```{r}
namesShort <- names(runsRaw) %>%
  stringr::str_remove("_disp.+") %>% 
  stringr::str_replace("Cut", "-C") %>% 
  stringr::str_remove("Cut1") %>% 
  stringr::str_replace("pdd", "P") %>% 
  stringr::str_replace("ndd", "N") %>% 
  stringr::str_replace_all("Var", "-L")
```

```{r}
names(runsRaw) <- namesShort
```

```{r}
S <- getSpecTime(runsRaw)
```

```{r}
Sp <- sapply(S, function(x){
  return(mean(x$spec_rich[99:200]))
})
Sp <- data.frame(meanSR = Sp, params = namesShort) 

Sp2 <- Sp %>%
  extract(params,
          into = c("P","PL","C"),
          regex = "P([0-9.]+)-L([0-9.]+)-C([0-9]+)",
          remove = FALSE)

base0 <- Sp2 %>% filter(P == 0, PL == 20)

# all NL values present in data
all_PL <- sort(unique(Sp2$PL))

# replicate for each NL
base0_expanded <- base0[rep(seq_len(nrow(base0)), length(all_PL)), ]
base0_expanded$PL <- rep(all_PL, each = nrow(base0))

# bind back
Sp2<- bind_rows(Sp2, base0_expanded)
```

```{r}
# ensure numeric
plotPDD <- ggplot(Sp2, aes(x = P, y = meanSR, color = factor(PL), group = PL)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  facet_wrap(~ C, ncol = 3, scales = "fixed",
             labeller = labeller(C = function(x) paste("pDD kernel =", x))) +
  labs(x = "pDD strength",
       y = "mean species richness",
       color = "pDD\nspecificity") +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "right",
    strip.text = element_text(size = 13, face = "bold"),
    panel.spacing = unit(1.5, "lines")   
  )

```

```{r}
pdf(paste0(root, "local/figures/mstr/20250807/metafor/pddEffect.pdf"), width = 8, height = 6, onefile = TRUE, useDingbats = FALSE)
print(plotPDD)
dev.off()
```

Next, we convert the matrix data into tabular data. With the argument detailedParams we include the parameter settings a seperate cols. We save the tabular data.

```{r}
#| eval: false

# convert matrices to tabular data. This is done parallel, as it takes longer
cl <- makeCluster(length(runsRaw))
clusterExport(cl, c("getMatToTab", "runsRaw"))
tab <- parLapply(cl = cl, X = runsRaw, fun = function(x) getMatToTab(x, detailedParams = TRUE))

saveRDS(tab, paste0(root, "local/runs/mstr/20250807/tab_fix-NL-N-nDC.rds"))
```

```{r}
tab <- readRDS(paste0(root, "local/runs/mstr/20250807/tab_fix-PL-P-pDC.rds"))
```

```{r}
namesShort <- names(tab_ix) %>%
  stringr::str_remove("_disp.+") %>% 
  stringr::str_remove("Cut1") %>% 
  stringr::str_remove("Cut1") %>% 
  stringr::str_replace("pdd", "P") %>% 
  stringr::str_replace("ndd", "N") %>% 
  stringr::str_replace_all("Var", "-L")
```

Now, we delete every second generation. Remember, we had to calculate the death in the consequent generation. After doing so, the generation x + 1 is no longer needed and is discarded.

```{r}
# keep only first timespot in census
tab_ixS <- lapply(tab_ix, function(x){
  res <- x %>%
  dplyr::filter(census %% 2 == 0,
          abund > 100) %>%
    mutate(specIdCen = paste0(specId, census)) %>% 
    dplyr::select(-fbmr, -sr, -fao, -disp, -indId)
  return(res)
})

names(tab_ixS) <- namesShort
```

### Metafor analysis: correcting for uncertainty

```{r}
#| eval: false

cl <- makeCluster(length(tab_ixS))

mcS_err <- parLapply(cl, tab_ixS, function(x) {
  specIDs <- unique(x$specIdCen)
  res <- vector("list", length(specIDs))
  
  i <- 1
  for (sID in specIDs) {
    dat <- x[x$specIdCen == sID, ]
    mod <- glm(mortNextGen ~ con, data = dat, family = binomial())
    sfm <- summary(mod)$coefficients
    vc <- vcov(mod)[c("(Intercept)", "con"), c("(Intercept)", "con")]

    mort0 <- plogis(coef(mod)[1])
    mort1 <- plogis(coef(mod)[1] + coef(mod)[2])
    
    res[[i]] <- list(
      specId = sID,
      abund = dat$abund[1],
      mort_change = mort1 - mort0,
      coef = coef(mod)[c(1,2)],
      vcov = vc
    )
    i <- i + 1
  }
  return(res)
})

# Stop the cluster
stopCluster(cl)
```

## compute variance of the marginal effect through a "posterior" simulation

```{r}
#| eval: false

cl <- makeCluster(length(mcS_err))
mcS_err_sim <- parLapply(cl, mcS_err, function(x){
  lapply(x, function(y){
    sim <- MASS::mvrnorm(n = 100, mu = c(y$coef[1], y$coef[2]), Sigma = y$vcov)
    mort0 <- plogis(sim[, 1])
    mort1 <- plogis(sim[, 1] + sim[, 2])
    mort_diff <- mort1 - mort0
    
    return(data.frame(
      abund = y$abund,
      specId = y$specId,
      mean = mean(mort_diff),
      se = sd(mort_diff),
      ci_low = quantile(mort_diff, 0.025),
      ci_high = quantile(mort_diff, 0.975)
    ))
  })
})
# Stop the cluster
stopCluster(cl)
```

## unlist inner lists and add log abund

```{r}
#| eval: false

m4 <- lapply(mcS_err_sim, function(group) {
  do.call(rbind, group)
})

m4 <- lapply(m4, function(group) {
  row.names(group) <- NULL
  group <- group %>% 
    mutate(log_N = log(abund))
  return(group)
})
```

## fitting model

```{r}
#| eval: false

dat_meta <- lapply(m4, function(x) {
  escalc(measure = "GEN", yi = mean, sei = se, slab = specId, data = x)
})
```

```{r}
#| eval: false

# # Detect available cores and create a cluster
# cl <- makeCluster(length(dat_meta))
# 
# # Export needed objects and packages to the workers
# clusterExport(cl, varlist = c("dat_meta"), envir = environment())
# 
# # Run in parallel
# metamod <- parLapply(cl, dat_meta, function(x) {
#   metafor::rma(
#     yi = yi,
#     vi = vi,
#     mods = ~ log_N,
#     method = "REML",
#     data = x
#   )
# })
# 
# # Stop cluster
# stopCluster(cl)
# 
# names(metamod) <- namesShort
```

```{r}
cl <- makeCluster(length(dat_meta))
clusterExport(cl, varlist = c("dat_meta"), envir = environment())

metamod <- parLapply(cl, dat_meta, function(x) {
  tryCatch({
    metafor::rma(
      yi = yi,
      vi = vi,
      mods = ~ log_N,
      method = "REML",
      data = x
    )
  }, error = function(e) {
    return(NULL)  # Return NULL for failed models
  })
})

stopCluster(cl)

# Remove NULL elements and keep names aligned
failed_indices <- sapply(metamod, is.null)
metamod <- metamod[!failed_indices]
names(metamod) <- namesShort[!failed_indices]

# Report which models failed
if(any(failed_indices)) {
  cat("Failed models:", paste(namesShort[failed_indices], collapse = ", "), "\n")
}
```

```{r}

# deleting one scenario

saveRDS(dat_meta, paste0(root, "local/runs/mstr/20250807/dat_metaix.rds"))
saveRDS(metamod, paste0(root, "local/runs/mstr/20250807/metamodix.rds"))


# metamod <- readRDS(paste0(root, "local/runs/mstr/20250807/metamodiii.rds"))
# dat_meta <- readRDS(paste0(root, "local/runs/mstr/20250807/dat_metaiii.rds"))
```

## predictions

### log_N

```{r}

pred <- lapply(dat_meta, function(x){
  expand_grid(log_N = seq(min(x$log_N, na.rm = TRUE),
                          max(x$log_N, na.rm = TRUE),
                          length.out = 1000))
})
pred <- lapply(pred, function(x){
  x$abund <- exp(x$log_N)
  return(x)
})
# Bind predictions to dataframe
pred <- lapply(seq_along(pred), function(i){
  x <- pred[[i]]
  y <- metamod[[i]]
  
  return(cbind(x, predict(object = y, newmods = x$log_N)))
})

names(pred) <- namesShort
```

```{r}
# Function to extract parameters from names (ignoring Cut3)
extract_params <- function(name) {
  # Remove Cut3 from the name first
  name_clean <- gsub("Cut3_", "_", name)
  
  # Extract P, N, and L values from names like "P0.5-L20_N0-L20"
  p_part <- sub("_.*", "", name_clean)  # Get part before underscore
  n_part <- sub(".*_", "", name_clean)  # Get part after underscore
  
  # Extract P and PL values
  p_val <- as.numeric(sub("-.*", "", sub("P", "", p_part)))
  pl_val <- as.numeric(sub(".*-L", "", p_part))
  
  # Extract N and NL values  
  n_val <- as.numeric(sub("-.*", "", sub("N", "", n_part)))
  nl_val <- as.numeric(sub(".*-L", "", n_part))
  
  return(data.frame(P = p_val, PL = pl_val, N = n_val, NL = nl_val))
}

# Convert pred list to dataframe with parameters
pred_df <- do.call(rbind, lapply(seq_along(pred), function(i) {
  df <- pred[[i]]
  params <- extract_params(names(pred)[i])
  df$scenario <- names(pred)[i]
  df$P <- params$P
  df$PL <- params$PL
  df$N <- params$N
  df$NL <- params$NL
  return(df)
}))

# Assume predict() returns fitted values and confidence intervals
# Adjust column names based on your actual metafor predict output
colnames(pred_df)[colnames(pred_df) == "pred"] <- "fitted"
if("ci.lb" %in% colnames(pred_df)) {
  pred_df$ci_lower <- pred_df$ci.lb
  pred_df$ci_upper <- pred_df$ci.ub
} 

# Create the null reference (P0, N0)
null_data <- pred_df[pred_df$P == 0 & pred_df$N == 0, ]

# Create individual plots for each scenario combination

# Get all unique P and N combinations
p_values <- sort(unique(pred_df$P))
n_values <- sort(unique(pred_df$N))

plots_list <- list()
plot_counter <- 1

# Loop through each P value
for (p_val in p_values) {
  # Loop through each N value  
  for (n_val in n_values) {
    
    # Skip null scenario as separate plot
    if (p_val == 0 & n_val == 0) next
    
    # Get data for this specific P,N combination
    plot_data <- pred_df[pred_df$P == p_val & pred_df$N == n_val, ]
    
    # Skip if no data
    if (nrow(plot_data) == 0) next
    
    # Create color/fill variable based on lambda values
    if (p_val == 0) {
      # Only N varies, color by NL
      plot_data$group_var <- paste0("NL", plot_data$NL)
      legend_title <- "N Lambda"
    } else if (n_val == 0) {
      # Only P varies, color by PL  
      plot_data$group_var <- paste0("PL", plot_data$PL)
      legend_title <- "P Lambda"
    } else {
      # Both P and N vary, color by combination
      plot_data$group_var <- paste0("PL", plot_data$PL, "_NL", plot_data$NL)
      legend_title <- "PL_NL"
    }
    
    # Count number of unique groups (lines) that will be plotted
    n_groups <- length(unique(plot_data$group_var))
    show_errors <- n_groups <= 4  # Show errors only if 4 or fewer lines
    
    # Create base plot
    p <- ggplot()
    
    # Add null reference (always with errors for reference)
    p <- p +
      geom_ribbon(data = null_data, aes(x = abund, ymin = ci_lower, ymax = ci_upper), 
                  alpha = 0.2, fill = "gray50") +
      geom_line(data = null_data, aes(x = abund, y = fitted), 
                color = "black", linetype = "dashed", size = 1.2, alpha = 0.8)
    
    # Add treatment lines conditionally with/without errors
    if (show_errors) {
      # Include error ribbons when 4 or fewer lines
      p <- p +
        geom_ribbon(data = plot_data, aes(x = abund, ymin = ci_lower, ymax = ci_upper, 
                                         fill = group_var), alpha = 0.3) +
        geom_line(data = plot_data, aes(x = abund, y = fitted, color = group_var), 
                  size = 1.2)
    } else {
      # Only lines when more than 4 groups (no error ribbons)
      p <- p +
        geom_line(data = plot_data, aes(x = abund, y = fitted, color = group_var), 
                  size = 1.2)
    }
    
    # Add labels and theme
    p <- p +
      scale_x_log10() +
      labs(title = paste0("P = ", p_val, ", N = ", n_val, " (", n_groups, " scenarios)"), 
           x = "Abundance per Census", y = "Mortality Change",
           color = legend_title, fill = legend_title) +
      theme_minimal() +
      theme(legend.position = "bottom",
            plot.title = element_text(size = 14, hjust = 0.5))
    
    # Store plot
    plots_list[[plot_counter]] <- p
    names(plots_list)[plot_counter] <- paste0("P", p_val, "_N", n_val)
    plot_counter <- plot_counter + 1
  }
}

# Create separate null plot (always with errors)
null_plot <- ggplot() +
  geom_ribbon(data = null_data, aes(x = abund, ymin = ci_lower, ymax = ci_upper), 
              alpha = 0.3, fill = "black") +
  geom_line(data = null_data, aes(x = abund, y = fitted), 
            color = "black", size = 1.5) +
  scale_x_log10() +
  labs(title = "Null Scenario: P = 0, N = 0", 
       x = "Abundance per Census", y = "Mortality Change") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, hjust = 0.5))

# Add null plot to list
plots_list[["null"]] <- null_plot

# Apply consistent scales to all plots
x_range <- range(pred_df$abund[pred_df$abund > 0 & is.finite(pred_df$abund)], na.rm = TRUE)
y_range <- range(c(pred_df$ci_lower, pred_df$ci_upper), na.rm = TRUE)

common_scales <- list(
  scale_x_log10(limits = x_range, expand = expansion(mult = 0.02)),
  coord_cartesian(ylim = y_range)
)

# Apply scales to all plots
plots_list <- lapply(plots_list, function(p) p + common_scales)

# Print summary information
cat("Total number of plots:", length(plots_list), "\n")
cat("Plot names:", names(plots_list), "\n")

# Count plots with/without error ribbons
plots_with_errors <- 0
plots_without_errors <- 0

for (i in seq_along(plots_list)) {
  if (names(plots_list)[i] != "null") {
    # Extract P and N values from plot name to get the data
    plot_name <- names(plots_list)[i]
    p_val <- as.numeric(sub("P([0-9.]+)_N.*", "\\1", plot_name))
    n_val <- as.numeric(sub(".*_N([0-9.]+)", "\\1", plot_name))
    
    plot_data <- pred_df[pred_df$P == p_val & pred_df$N == n_val, ]
    if (p_val == 0) {
      group_var <- paste0("NL", plot_data$NL)
    } else if (n_val == 0) {
      group_var <- paste0("PL", plot_data$PL)
    } else {
      group_var <- paste0("PL", plot_data$PL, "_NL", plot_data$NL)
    }
    n_groups <- length(unique(group_var))
    
    if (n_groups <= 4) {
      plots_with_errors <- plots_with_errors + 1
    } else {
      plots_without_errors <- plots_without_errors + 1
    }
  }
}

cat("Plots with error ribbons (≤4 lines):", plots_with_errors, "\n")
cat("Plots without error ribbons (>4 lines):", plots_without_errors, "\n\n")

# Display all plots
for (i in seq_along(plots_list)) {
  cat("Displaying plot:", names(plots_list)[i], "\n")
  print(plots_list[[i]])
}
```

## save PDF

```{r}
pdf(paste0(root, "local/figures/mstr/20250807/metafor/overwriting_protection.pdf"), width = 8, height = 6, onefile = TRUE, useDingbats = FALSE)
lapply(plots_list, print)   # each print() → new page
dev.off()
```

# compare correlation (slope) with max species abundance and SR

```{r}

datmeta <- readRDS(paste0(root, "local/runs/mstr/20250807/dat_metaix.rds"))
metamod <- readRDS(paste0(root, "local/runs/mstr/20250807/metamodix.rds"))
runs <- readRDS(paste0(root, "local/runs/mstr/20250807/runs_ix.rds"))
```

```{r}
convert_name <- function(nm) {
  # split into parts
  parts <- strsplit(nm, "_")[[1]]
  
  # parse NDD
  n_part <- sub("ndd", "", parts[1])
  n_val  <- sub("var.*", "", n_part)
  nl_val <- sub(".*var", "", n_part)
  
  # parse PDD
  p_part <- sub("pdd", "", parts[2])
  p_val  <- sub("var.*", "", p_part)
  pl_val <- sub(".*var", "", p_part)
  
  paste0("P", p_val, "-L", pl_val, "_N", n_val, "-L", nl_val)
}
```

```{r}
# get slopes
slope <- sapply(metamod, function(x){
  ret <- coef(x)[2]
  return(ret)
})
res <- as.data.frame(slope)
rownames(res) <- names(metamod)

# get abundance
abund <- sapply(datmeta, function(x){
  return(quantile(x = x$abund, probs = .90))
})
abund <- data.frame(
  param = names(datmeta),
  abund    = abund
)

# get sr and rename
srRaw <- getSpecTime(runs, plot = FALSE)
names_converted <- vapply(names(srRaw), convert_name, FUN.VALUE = character(1))

names(srRaw) <- names_converted

sr <- sapply(srRaw, function(x) {
  vals <- x$spec_rich[101:300]
  c(meanSR = mean(vals), sdSR = sd(vals), medianSR = median(vals))
}) %>% t() %>%  as.data.frame()

res <- res %>% 
  rownames_to_column("param") %>% 
  left_join(
    sr %>% 
      rownames_to_column("param"),
    by = "param"
  ) %>% 
  left_join(
    abund, by = "param"
  ) %>% 
  mutate( medianSR = as.integer(medianSR))
```

```{r}
#| fig-width: 6
#| fig-height: 5

# model
fm1 <- lm(formula = meanSR ~ slope, data = res)
fm2 <- glm(formula = abund ~ slope, data = res, family = "poisson")
newdat <- data.frame(slope = seq(min(res$slope), max(res$slope), length = 100))
predi <- predict(fm1, newdata = newdat, se.fit = TRUE)
predii <- predict(fm2, newdata = newdat, se.fit = TRUE, type = "response")

# plot
plot(x = res$slope, y = res$meanSR, ylim = c(40,90), pch = 16, col = "blue",
     xlab = "mortality change ~ abundance: slope", ylab = "mean species richness")
points(x = res$slope, y = res$medianSR, pch = 16, col = "red")
arrows(x0 = res$slope, y0 = res$meanSR - res$sdSR,
       x1 = res$slope, y1 = res$meanSR + res$sdSR,
       angle = 90, code = 3, length = 0.05)
lines(x = newdat$slope, y = predi$fit, lwd = 2 , col = 1)
lines(x = newdat$slope, y = predi$fit - 2 * predi$se.fit, lwd = 1, lty = 2, col = 1)
lines(x = newdat$slope, y = predi$fit + 2 * predi$se.fit, lwd = 1, lty = 2, col = 1)
legend("bottomleft", legend = c("mean SR", "median SR", "fitted lm", "CI"), pch = c(16,16,NA,NA), lty = c(NA,NA, 1,2), col = c(4,2,1,1), bty = "n")
text(x = -0.001, y = 90, "*** P < 0.001", cex = 1)

# ---------------

# also tried poisson, looks the same, dharma looks OK

plot(x = res$slope, y = res$abund, pch = 16, col = 1,
     xlab = "mortality change ~ abundance: slope", ylab = "mean species richness")
lines(x = newdat$slope, y = predii$fit, lwd = 2 , col = 1)
lines(x = newdat$slope, y = predii$fit - 2 * predi$se.fit, lwd = 1, lty = 2, col = 1)
lines(x = newdat$slope, y = predii$fit + 2 * predi$se.fit, lwd = 1, lty = 2, col = "grey")
legend("topleft", legend = c("mean SR", "fitted glm pois", "CI"), pch = c(16,NA,NA), lty = c(NA, 1,2), col = c(1,1,1), bty = "n")
text(x = -0.0015, y = 3300, "*** P < 0.001", cex = 1)

#-----------------

```

```{r}
summary(fm1)
```

